# RL-at-Harvard-tutorial-2022

<p align="center">
<img src="https://github.com/john-vastola/RL-at-Harvard-tutorial-2022/blob/main/images/RL_pacman_schematic.png?raw=true" alt="drawing" width="600"/>
</p>


**Welcome to the reinforcement learning tutorial!** The goal of this tutorial is to present a brief introduction to

(i) the basic concepts of reinforcement learning (RL), and 

(ii) how those concepts might relate to the brain. 

This companion notebook contains demos which complement the main presentation, plus summaries of some of the essential points. It is self-contained, and only uses basic Python packages.

The structure of the notebook is as follows:

1.   The Rescorla-Wagner model of classical conditioning
2.   Generalizing Rescorla-Wagner using the temporal difference learning model
3.   Intermission: Mathematical formulation of reinforcement learning problems 
4.   Temporal difference learning as a general model-free prediction algorithm
5.   Q-learning and actor-critic: two general model-free control algorithms

For more details on everything discussed here, take a look at Sutton and Barto's classic RL textbook. Often considered the 'bible' of RL, it is a must-read if you are serious about learning the subject. 

Read it for free on Sutton's website here: http://incompleteideas.net/book/the-book-2nd.html
